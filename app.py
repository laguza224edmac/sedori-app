import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import statistics
import urllib.parse
from pyzbar.pyzbar import decode
from PIL import Image
import re

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ãƒ—ãƒ­ãƒ»ãƒãƒ³ã‚¿ãƒ¼ v9.1", layout="wide")

st.title("ğŸ‘‘ ãƒ—ãƒ­ãƒ»ãƒãƒ³ã‚¿ãƒ¼ v9.1 (å®Œå…¨ç‰ˆ)")
st.write("ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ Ã— åˆ©ç›Šã‚¢ãƒ©ãƒ¼ãƒˆ Ã— ã‚¸ãƒ£ãƒ³ã‚¯é™¤å¤– ã®æœ€å¼·å½¢æ…‹ï¼")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("âš™ï¸ ãƒãƒ³ã‚¿ãƒ¼è¨­å®š")
input_mode = st.sidebar.radio("æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰", ["ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èª­ã¿å–ã‚Š", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›"])
alert_threshold = st.sidebar.number_input("åˆ©ç›Šã‚¢ãƒ©ãƒ¼ãƒˆã®åŸºæº–ï¼ˆå††ï¼‰", value=2000, step=500)
shipping_cost = st.sidebar.number_input("é€æ–™ï¼ˆå††ï¼‰", value=750, step=50)
exclude_junk = st.sidebar.checkbox("ã€Œã‚¸ãƒ£ãƒ³ã‚¯ãƒ»ã‚±ãƒ¼ã‚¹ã®ã¿ã€ã‚’é™¤å¤–", value=True) # â˜…å®Œå…¨å¾©æ´»ï¼

keyword = ""

# --- ã‚«ãƒ¡ãƒ©ã§ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èª­ã¿å–ã‚Š ---
if input_mode == "ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èª­ã¿å–ã‚Š":
    st.info("ğŸ‘‡ ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®å†™çœŸã‚’æ’®ã£ã¦ãã ã•ã„")
    img_file_buffer = st.camera_input("ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³")
    if img_file_buffer:
        image = Image.open(img_file_buffer)
        decoded = decode(image)
        if decoded:
            keyword = decoded[0].data.decode("utf-8")
            st.success(f"ğŸ¯ èª­ã¿å–ã‚ŠæˆåŠŸ: {keyword}")
        else:
            st.error("èª­ã¿å–ã‚Šå¤±æ•—... æ˜ã‚‹ã„å ´æ‰€ã§ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ï¼")
else:
    keyword = st.sidebar.text_input("æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›", "iPhone 12")

# --- â˜…æ–°æ©Ÿèƒ½ï¼šã‚´ãƒŸã‚’å¼¾ãå¼·åŠ›ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ---
def is_junk(title):
    if not exclude_junk:
        return False
    # ã“ã“ã«æ›¸ã‹ã‚ŒãŸè¨€è‘‰ãŒå…¥ã£ã¦ã„ã‚‹å•†å“ã¯ç„¡è¦–ã—ã¾ã™ï¼
    junk_words = ["ã‚¸ãƒ£ãƒ³ã‚¯", "JUNK", "è¨³ã‚ã‚Š", "é›£ã‚ã‚Š", "ã‚±ãƒ¼ã‚¹ã®ã¿", "ã‚±ãƒ¼ã‚¹ã ã‘", "ç©ºç®±"]
    for word in junk_words:
        if word in title:
            return True
    return False

# --- ä¾¡æ ¼å–å¾—ã®ãŸã‚ã®è£æ–¹ãƒ„ãƒ¼ãƒ« ---
def get_yahoo_price(kw):
    url = f"https://auctions.yahoo.co.jp/closedsearch/closedsearch?p={kw}" # éå»ã®è½æœ­ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’è¦‹ã‚‹ï¼
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        prices = []
        for item in soup.find_all("li", class_="Product"):
            t = item.find("a", class_="Product__titleLink")
            p = item.find("span", class_="Product__priceValue")
            if t and p:
                if is_junk(t.text): # ã‚¸ãƒ£ãƒ³ã‚¯ã‚„ã‚±ãƒ¼ã‚¹ã‚’å¼¾ãï¼
                    continue
                price_text = p.text.replace("å††", "").replace(",", "").strip()
                if price_text.isdigit():
                    prices.append(int(price_text))
        return int(statistics.mean(prices)) if prices else 0
    except:
        return 0

def get_rakuten_price(kw):
    # æ¥½å¤©ã¯æ—¥æœ¬èªã®URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦
    safe_kw = urllib.parse.quote(kw)
    url = f"https://search.rakuten.co.jp/search/mall/{safe_kw}/"
    # ã‚¹ãƒãƒ›ã‚„PCã®ã€Œæ™®é€šã®ãƒ–ãƒ©ã‚¦ã‚¶ã€ã®ãƒ•ãƒªã‚’ã™ã‚‹ï¼ˆæ€ªã—ã¾ã‚Œãªã„ã‚ˆã†ã«é•·ãã™ã‚‹ï¼‰
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        prices = []
        # ä½œæˆ¦1ï¼šåå‰ã«ã€Œpriceã€ãŒå«ã¾ã‚Œã‚‹å ´æ‰€ã‚’å…¨éƒ¨æ¢ã™
        price_tags = soup.find_all(class_=re.compile("price", re.IGNORECASE))
        
        for tag in price_tags:
            text = tag.get_text()
            # ã€Œ1,980å††ã€ãªã©ã‹ã‚‰ã€æ•°å­—ä»¥å¤–ã®æ–‡å­—ã‚’å…¨éƒ¨æ¶ˆã—å»ã‚‹ï¼
            num_str = re.sub(r'\D', '', text) 
            if num_str:
                prices.append(int(num_str))
        
        # æ¥µç«¯ã«å®‰ã„ã‚‚ã®ï¼ˆé€æ–™è¡¨ç¤ºã®100å††ãªã©ï¼‰ã‚’çœããŸã‚ã€500å††ä»¥ä¸Šã®æœ€å®‰å€¤ã«ã™ã‚‹
        valid_prices = [p for p in prices if p > 500]
        return min(valid_prices) if valid_prices else 0
        
    except Exception as e:
        print(f"æ¥½å¤©ã‚¨ãƒ©ãƒ¼: {e}") # ã‚‚ã—ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‚ã‚¢ãƒ—ãƒªãŒæ­¢ã¾ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
        return 0

# --- ãƒ¡ã‚¤ãƒ³ã®ãƒªã‚µãƒ¼ãƒå‡¦ç† ---
if keyword:
    st.divider()
    if st.button("ğŸš€ å…¨å¸‚å ´ä¸€æ–‰ãƒªã‚µãƒ¼ãƒé–‹å§‹ï¼"):
        with st.spinner('å„å¸‚å ´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨åŠ›ã§è¨ˆç®—ä¸­...'):
            yahoo_avg = get_yahoo_price(keyword)
            rakuten_min = get_rakuten_price(keyword)
            
            # --- ç”»é¢è¡¨ç¤ºï¼šç›¸å ´æ¯”è¼ƒ ---
            st.markdown("### ğŸ“Š å¸‚å ´ã®ç›¸å ´ãƒã‚§ãƒƒã‚¯")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ãƒ¤ãƒ•ã‚ªã‚¯è½æœ­ç›¸å ´ (éå»ã®å®Ÿç¸¾)", f"{yahoo_avg:,}å††")
            with col2:
                st.metric("æ¥½å¤©æœ€å®‰å€¤ (æ–°å“ç›®å®‰)", f"{rakuten_min:,}å††")

            st.divider()

            # --- ãƒ¤ãƒ•ã‚ªã‚¯ã§ç¾åœ¨å‡ºå“ä¸­ã®åˆ©ç›Šå•†å“ã‚’ãƒã‚§ãƒƒã‚¯ ---
            st.info("ç¾åœ¨å‡ºå“ä¸­ã®ãŠå®ã‚’æ¢ã—ã¦ã„ã¾ã™...")
            url_current = f"https://auctions.yahoo.co.jp/search/search?p={keyword}" # ç¾åœ¨ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³ä¸­ã‹ã‚‰æ¢ã™
            res_curr = requests.get(url_current, headers={"User-Agent": "Mozilla/5.0"})
            soup_curr = BeautifulSoup(res_curr.text, 'html.parser')
            
            current_items = []
            for item in soup_curr.find_all("li", class_="Product")[:15]: 
                t = item.find("a", class_="Product__titleLink")
                p = item.find("span", class_="Product__priceValue")
                if t and p:
                    title_text = t.text.strip()
                    if is_junk(title_text): # ã“ã“ã§ã‚‚ã‚¸ãƒ£ãƒ³ã‚¯ã‚„ã‚±ãƒ¼ã‚¹ã‚’å¼¾ãï¼
                        continue
                    price = int(p.text.replace("å††", "").replace(",", "").strip())
                    profit = int((yahoo_avg * 0.9) - shipping_cost - price)
                    current_items.append({"å•†å“å": title_text, "ä¾¡æ ¼": price, "åˆ©ç›Š": profit, "URL": t.get("href")})
            
            if current_items:
                df = pd.DataFrame(current_items).sort_values(by="åˆ©ç›Š", ascending=False)
                best = df.iloc[0]

                # === â˜…åˆ©ç›Šã‚¢ãƒ©ãƒ¼ãƒˆâ˜… ===
                if best["åˆ©ç›Š"] >= alert_threshold:
                    st.balloons()
                    st.toast("ãŠå®ç™ºè¦‹ï¼åŸºæº–ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼", icon="ğŸ’°")
                    st.error(f"ğŸš¨ ã€æ¿€ã‚¢ãƒ„ã€‘äºˆæƒ³åˆ©ç›Š +{best['åˆ©ç›Š']:,}å†† ã®å•†å“ãŒã‚ã‚Šã¾ã™ï¼")
                    st.markdown(f"**ç‹™ã„ç›®å•†å“:** [{best['å•†å“å']}]({best['URL']})")
                else:
                    st.info(f"ç¾åœ¨ã®æœ€é«˜åˆ©ç›Šï¼š+{best['åˆ©ç›Š']:,}å††ï¼ˆè¨­å®šã—ãŸåŸºæº–ã¾ã§ã‚ã¨ {alert_threshold - best['åˆ©ç›Š']}å††ï¼‰")

                # ãƒªã‚¹ãƒˆè¡¨ç¤ºï¼ˆã‚­ãƒ¬ã‚¤ãªè¡¨ã«ã—ã¾ã—ãŸï¼ï¼‰
                st.write("### ğŸ“‹ ãƒªã‚µãƒ¼ãƒãƒªã‚¹ãƒˆ")
                st.dataframe(
                    df,
                    column_config={
                        "URL": st.column_config.LinkColumn("å•†å“ãƒšãƒ¼ã‚¸ã¸"),
                        "ä¾¡æ ¼": st.column_config.NumberColumn(format="%då††"),
                        "åˆ©ç›Š": st.column_config.NumberColumn(format="%då††"),
                    },
                    hide_index=True
                )
            else:
                st.warning("ç¾åœ¨å‡ºå“ä¸­ã®ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆã‚¸ãƒ£ãƒ³ã‚¯ä»¥å¤–ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")